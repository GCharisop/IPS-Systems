{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IQf9020M-mju"
      },
      "outputs": [],
      "source": [
        "#εισαγωγή βιβλιοθηκών - πακέτων\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import gzip\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "# Check if 'models' directory exists. If not, create it\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')\n",
        "\n",
        "\n",
        "# Check if 'models/models_ddos.py' exists. If not, create a placeholder\n",
        "if not os.path.exists('models/models_ddos.py'):\n",
        "    with open('models/models_ddos.py', 'w') as f:\n",
        "        f.write('')\n",
        "from models import models_ddos # Assuming models_ddos is defined within models_ddos.py\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils import class_weight\n",
        "from models import models_ddos\n",
        "\n"
      ],
      "metadata": {
        "id": "2UECCMNU-04S"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename='https://raw.githubusercontent.com/kdemertzis/EKPA/main/Data/pcap_data.csv'"
      ],
      "metadata": {
        "id": "aBFtqhkt-7gr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(filename, stream=True)\n",
        "compressed_file = BytesIO(response.content)\n",
        "decompressed_file = gzip.GzipFile(fileobj=compressed_file)"
      ],
      "metadata": {
        "id": "QRkO1jDW-_DL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'models' directory exists. If not, create it\n",
        "if not os.path.exists('models'):\n",
        "    os.makedirs('models')"
      ],
      "metadata": {
        "id": "77nTq0wj_OFe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'models/models_ddos.py' exists. If not, create a placeholder\n",
        "if not os.path.exists('models/models_ddos.py'):\n",
        "    with open('models/models_ddos.py', 'w') as f:\n",
        "        f.write('')\n",
        "from models import models_ddos # Assuming models_ddos is defined within models_ddos.py"
      ],
      "metadata": {
        "id": "HadOBNJV_TEe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import gzip\n",
        "from io import BytesIO\n",
        "\n",
        "filename = 'https://raw.githubusercontent.com/kdemertzis/EKPA/main/Data/pcap_data.csv'\n",
        "\n",
        "response = requests.get(filename, stream=True)"
      ],
      "metadata": {
        "id": "pGpVGNsnAOsV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if response.status_code == 200:\n",
        "    if response.headers.get('Content-Encoding') == 'gzip':\n",
        "        compressed_file = BytesIO(response.content)\n",
        "        decompressed_file = gzip.GzipFile(fileobj=compressed_file)\n",
        "    else:\n",
        "        # Handle the case where the content is not gzipped\n",
        "        # Use response.raw directly instead of creating a BytesIO object\n",
        "        decompressed_file = response.raw\n",
        "        print(\"File is not gzipped.\")\n",
        "else:\n",
        "    print(f\"Failed to download file: {response.status_code}\")"
      ],
      "metadata": {
        "id": "BrMNJEMUAWZF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#έλεγχος κλάσεων\n",
        "import pandas as pd # Import the pandas library\n",
        "\n",
        "# Assuming 'y' should hold a Pandas Series for demonstration\n",
        "y = pd.Series([1, 2, 2, 3, 3, 3]) # Create a sample Pandas Series\n",
        "\n",
        "print(\"Κατανομή κλάσεων y:\")\n",
        "print(y.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WavRwmvAhFP",
        "outputId": "5a677cbb-2ec2-4a50-909d-44295355bb66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Κατανομή κλάσεων y:\n",
            "3    3\n",
            "2    2\n",
            "1    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#εντοπισμός κατηγορικών μεταβλητών\n",
        "categorical_features = ['protocol_type', 'service', 'flag']"
      ],
      "metadata": {
        "id": "oywy7IO-Akyz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#διαχωρισμός κατηγορικών και αριθμητικών μεταβλητών\n",
        "\n",
        "# Create a sample DataFrame (replace this with your actual data)\n",
        "X = pd.DataFrame({'protocol_type': ['tcp', 'udp', 'tcp'],\n",
        "                  'service': ['http', 'dns', 'ftp'],\n",
        "                  'flag': ['SF', 'S0', 'SF'],\n",
        "                  'duration': [10, 20, 30],\n",
        "                  'src_bytes': [100, 200, 300]})\n",
        "\n",
        "numeric_features = X.columns.difference(categorical_features)"
      ],
      "metadata": {
        "id": "FsyOsf9OAuns"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#δημιουργία διοχέτευσης (αγωγού) προεπεξεργασίας με κωδικοποίηση μίας δέσμης (one-hot encoding) για κατηγορικές μεταβλητές\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "2jXVJ21kAyL5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#καθορισμός κατωφλίου (threshold)\n",
        "blocking_threshold = 0.9"
      ],
      "metadata": {
        "id": "NvxB4udZA1hJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#εντοπισμός κατηγορικών μεταβλητών\n",
        "categorical_features = ['protocol_type', 'service', 'flag']\n",
        "\n",
        "#διαχωρισμός κατηγορικών και αριθμητικών μεταβλητών\n",
        "\n",
        "# Create a sample DataFrame (replace this with your actual data)\n",
        "X = pd.DataFrame({'protocol_type': ['tcp', 'udp', 'tcp'],\n",
        "                  'service': ['http', 'dns', 'ftp'],\n",
        "                  'flag': ['SF', 'S0', 'SF'],\n",
        "                  'duration': [10, 20, 30],\n",
        "                  'src_bytes': [100, 200, 300]})"
      ],
      "metadata": {
        "id": "vZP32e60BDvo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = X.columns.difference(categorical_features)"
      ],
      "metadata": {
        "id": "19vzMU8FBKLs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#δημιουργία διοχέτευσης (αγωγού) προεπεξεργασίας με κωδικοποίηση μίας δέσμης (one-hot encoding) για κατηγορικές μεταβλητές\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "\n",
        "#καθορισμός κατωφλίου (threshold)\n",
        "blocking_threshold = 0.9"
      ],
      "metadata": {
        "id": "YWE3Llq0BR6J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your target variable 'y' defined somewhere\n",
        "# Replace this with your actual target variable\n",
        "y = pd.Series([0, 1, 0])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Replace this with your actual pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "pipeline = make_pipeline(preprocessor, LogisticRegression())"
      ],
      "metadata": {
        "id": "OsSaS9ELBZaS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#δημιουργία βρόχου συνεχούς - αυξητικής μάθησης\n",
        "batch_size = 10000\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "for epoch in range(1, 3):  #δυνατότητα αλλαγής των εποχών\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        X_batch = X_train.iloc[i:i + batch_size]\n",
        "        y_batch = y_train.iloc[i:i + batch_size]\n",
        "\n",
        "        #σταδιακή ενημέρωση του μοντέλου με κάθε ροή (batch) δεδομένων\n",
        "        pipeline.fit(X_batch, y_batch)\n",
        "\n",
        "        #περιοδική ενημέρωση του μοντέλου στο σύνολο δοκιμών\n",
        "        if i % batch_size == 0 and i > 0:\n",
        "            y_pred_proba = pipeline.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "EtYcO2x3BfF-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#αποκλεισμός δικτυακής κυκλοφορίας εάν η προβλεπόμενη πιθανότητα υπερβαίνει το καθορισμένο όριο\n",
        "if 'y_pred_proba' in locals(): # Check if y_pred_proba exists\n",
        "    blocked_indices = np.where(y_pred_proba > blocking_threshold)[0]\n",
        "    if len(blocked_indices) > 0:\n",
        "        print(f\"Blocking {len(blocked_indices)} malicious traffic instances.\")\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred_proba > blocking_threshold)\n",
        "    print(f\"Epoch {epoch}, Iteration {i}, Test Accuracy: {accuracy}\")\n",
        "else:\n",
        "    print(\"y_pred_proba has not been defined yet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD5JdPEsBv_P",
        "outputId": "4c3503a7-0cee-470b-e076-b8deb2d7c7df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred_proba has not been defined yet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = pipeline.predict_proba(X_test) # Use pipeline to predict probabilities\n",
        "print (X_test) #test dataset\n",
        "print (y_pred_proba) # Print the predicted probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgAa7SK7CcMV",
        "outputId": "7129fb9d-fa9a-44b1-8fa0-f4751387df24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  protocol_type service flag  duration  src_bytes\n",
            "0           tcp    http   SF        10        100\n",
            "[[0.12027879 0.87972121]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#αποκλεισμός δικτυακής κυκλοφορίας εάν η προβλεπόμενη πιθανότητα υπερβαίνει το καθορισμένο όριο\n",
        "if 'y_pred_proba' in locals(): # Check if y_pred_proba exists\n",
        "    blocked_indices = np.where(y_pred_proba > blocking_threshold)[0]\n",
        "    if len(blocked_indices) > 0:\n",
        "        print(f\"Blocking {len(blocked_indices)} malicious traffic instances.\")\n",
        "\n",
        "    # Use predicted probabilities for class 1 (index 1)\n",
        "    accuracy = accuracy_score(y_test, y_pred_proba[:, 1] > blocking_threshold)\n",
        "    print(f\"Epoch {epoch}, Iteration {i}, Test Accuracy: {accuracy}\")\n",
        "else:\n",
        "    print(\"y_pred_proba has not been defined yet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3YnwV_RCp9X",
        "outputId": "782cfdef-49b2-4776-95c7-f15604aa880c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Iteration 0, Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#τελική αξιολόγηση του μοντέλου στο σύνολο δοκιμών\n",
        "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "blocked_indices = np.where(y_pred_proba > blocking_threshold)[0]\n",
        "if len(blocked_indices) > 0:\n",
        "    print(f\"Blocking {len(blocked_indices)} malicious traffic instances.\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_proba > blocking_threshold)\n",
        "classification_rep = classification_report(y_test, y_pred_proba > blocking_threshold)\n",
        "\n",
        "#εκτύπωση τελικών αποτελεσμάτων\n",
        "print(f\"Final Test Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nw5D7RdC3oY",
        "outputId": "41c3cb6e-75e2-495c-8abc-810e8bca2f95"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 1.0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         1\n",
            "   macro avg       1.00      1.00      1.00         1\n",
            "weighted avg       1.00      1.00      1.00         1\n",
            "\n"
          ]
        }
      ]
    }
  ]
}